{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=blue>Ẩn dữ liệu và chia sẻ thông tin\n",
    "# <center><font color=blue>Đồ án môn học </font>\n",
    "# <center>ALASKA2 Image Steganalysis\n",
    "### <center>*Detect secret data hidden within digital images*</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giới thiệu thành viên và phân công công công việc:\n",
    "\n",
    "\n",
    "\n",
    "| Tên | MSSV | Nhiệm vụ | Hoàn thành |\n",
    "|:-------|-------|:-------|-------|\n",
    "| Nguyễn Trí Đức | 20120060 | Tiền xử lý dữ liệu, report | 100% |\n",
    "| Nguyễn Thế Anh | 20120248 | Tìm hiểu và xây dựng mô hình, report | 100% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giới thiệu chung về đồ án:\n",
    "\n",
    "Đồ án dựa trên cuộc thi [ALASKA2 Image Steganalysis](https://www.kaggle.com/competitions/alaska2-image-steganalysis) trên <font color=blue>__Kaggle__</font>. Những tệp hình ảnh tưởng chừng như \"vô hại\" có thể chứa đựng thông điệp ẩn được nhúng một cách tinh vi, khiến mắt thường khó lòng phát hiện. Machine learning là một công cụ quan trọng trong việc nhận diện những dữ liệu bí mật này.\n",
    "\n",
    "Trong đồ án này, chúng ta sẽ cần tạo ra một phương pháp hiệu quả và đáng tin cậy để phát hiện dữ liệu bí mật ẩn trong các hình ảnh kỹ thuật số tưởng chừng như vô hại. Thay vì giới hạn nguồn dữ liệu, những hình ảnh này đã được thu thập với 50 máy ảnh khác nhau (từ điện thoại thông minh đến máy ảnh cao cấp có định dạng đầy đủ) và được xử lý theo nhiều kiểu khác nhau. Phương pháp thành công sẽ bao gồm các thuật toán phát hiện mạnh mẽ với tỷ lệ sai sót tối thiểu. Cụ thể, là tạo ra một mô hình học máy phù hợp với độ chính xác cao để phân tích và tính toán xem các bức ảnh trong folder test có bị nhúng dữ liệu mật hay không."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mô tả Dataset:\n",
    "- Bộ dữ liệu này chứa một số lượng lớn các hình ảnh jpeg gốc gọi là \"Cover\" và các hình ảnh tương tự nhưng đã bị nhúng dữ liệu ẩn bằng các thuật toán steganography gồm JMiPOD, JUNIWARD, UERD. Mục tiêu của cuộc thi là xác định hình ảnh nào trong tập Test có thông điệp ẩn được nhúng.\n",
    "\n",
    "\n",
    "- Lưu ý rằng để làm cho cuộc thi thực tế hơn, độ dài của các thông điệp ẩn (payload) sẽ không được cung cấp. Thông tin duy nhất có sẵn trên tập kiểm tra là:\n",
    "    - Mỗi thuật toán nhúng được sử dụng với cùng một xác suất.\n",
    "    - Payload (độ dài thông điệp) được điều chỉnh sao cho \"độ khó\" là xấp xỉ như nhau bất kể nội dung của hình ảnh. Các hình ảnh với nội dung mượt mà sẽ được sử dụng để ẩn các thông điệp ngắn hơn trong khi các hình ảnh có kết cấu cao sẽ được sử dụng để ẩn nhiều bit bí mật hơn. Payload được điều chỉnh theo cách tương tự cho cả tập kiểm tra và tập huấn luyện.\n",
    "    - Độ dài thông điệp trung bình là 0.4 bit mỗi hệ số AC DCT khác không.\n",
    "    - Các hình ảnh đều được nén với một trong ba hệ số chất lượng JPEG sau: 95, 90 hoặc 75.\n",
    "    \n",
    "    \n",
    "- __Tập tin__:\n",
    "    - Cover/ chứa 75k hình ảnh gốc, dùng để huấn luyện.\n",
    "    - JMiPOD/ chứa 75k ví dụ về thuật toán JMiPOD được áp dụng lên các hình ảnh cover.\n",
    "    - JUNIWARD/ chứa 75k ví dụ về thuật toán JUNIWARD được áp dụng lên các hình ảnh cover.\n",
    "    - UERD/ chứa 75k ví dụ về thuật toán UERD được áp dụng lên các hình ảnh cover.\n",
    "    - Test/ chứa 5k hình ảnh của tập kiểm tra. Đây là các hình ảnh mà bạn cần dự đoán.\n",
    "    - sample_submission.csv chứa một ví dụ về bài nộp trong định dạng chính xác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài toán chi tiết:\n",
    "\n",
    "## Cách tính điểm trong cuộc thi [ALASKA2 Image Steganalysis](https://www.kaggle.com/competitions/alaska2-image-steganalysis):\n",
    "\n",
    "- __Giới thiệu về Đường cong ROC và AUC__:\n",
    "    - Đường cong ROC (Receiver Operating Characteristic) là một công cụ quan trọng trong đánh giá hiệu suất của các mô hình phân loại, biểu diễn khả năng phân loại các lớp của mô hình. Đường cong này thể hiện mối quan hệ giữa Tỷ Lệ Dương Tính Thực Sự (TPR - True Positive Rate) và Tỷ Lệ Dương Tính Giả (FPR - False Positive Rate) tại các ngưỡng khác nhau.\n",
    "    - Đặc điểm của đường cong ROC:\n",
    "        - Đường cong ROC càng gần góc trên bên trái của biểu đồ (điểm [0,1], nơi TPR = 1 và FPR = 0) thì hiệu suất của mô hình càng cao.\n",
    "        - Một đường cong đi từ góc dưới bên trái ([0,0]) đến góc trên bên phải ([1,1]) của biểu đồ, thể hiện mức độ phân biệt giữa các lớp của mô hình.\n",
    "        - Đây là ví dụ về đường cong ROC với ngưỡng 0.0 - 0.5 - 1.0 : [ROC Example](https://miro.medium.com/v2/resize:fit:1200/1*Bgc9QOjhnL70g2SQxyj6hQ.png)\n",
    "- __Khái niệm AUC__: AUC là diện tích dưới đường cong ROC (Receiver Operating Characteristic), đánh giá tổng thể hiệu quả phân loại của mô hình, với AUC = 1 chỉ ra hiệu quả tuyệt đối và AUC = 0.5 tương đương với dự đoán ngẫu nhiên.\n",
    "\n",
    "\n",
    "- __Trọng số của các vùng trên ROC curve__: \n",
    "    - Trong cuộc thi này, để nhấn mạnh vào độ chính xác của việc phát hiện với tỉ lệ báo động sai thấp, AUC có trọng số (weighted AUC) được sử dụng. Các vùng khác nhau của ROC curve được tính trọng số theo các tham số đã chọn:\n",
    "        - `tpr_thresholds = [0.0, 0.4, 1.0]` - true positive rate được chia thành 3 vùng 0.0; 0.4 và 1.0\n",
    "        - `weights = [2, 1]` - trọng số từ 0 đến 0.4 là 2 và trọng số từ 0.4 đến 1 là 1\n",
    "    - Điều này có nghĩa là diện tích giữa TPR 0 và 0.4 được tính trọng số là 2, và diện tích giữa 0.4 và 1 được tính trọng số là 1.\n",
    "    \n",
    "    \n",
    "- __Công thức tính__:\n",
    "    - Đầu tiên, chia ROC curve thành các vùng dựa trên các ngưỡng TPR đã cho.\n",
    "    - Sau đó, tính toán diện tích dưới đường cong ROC trong mỗi vùng.\n",
    "    - Diện tích của mỗi vùng được nhân với trọng số tương ứng.\n",
    "    - Tổng diện tích có trọng số được chuẩn hóa bằng tổng của các trọng số ( 2 + 1 = 3 ) để đảm bảo rằng AUC cuối cùng nằm trong khoảng từ 0 đến 1.\n",
    "    - Ví dụ : \n",
    "        - Gọi $S_1$ là phần diện tích dưới đường cong ROC của vùng 1 ứng với trọng số $W_1$.\n",
    "        - $S_2$ là phần diện tích dưới đường cong của vùng 2 ứng với trọng số $W_1$.\n",
    "        - Ta có công thức tính weighted AUC:\n",
    "\n",
    "\n",
    "<center>$wAUC = \\frac{W_1.S_1 + W_2.S_2}{W_1+W_2} = \\frac{2.S_1 + S_2}{3}$</center>\n",
    "\n",
    "\n",
    "- __Nhận xét__: $S_1$ sẽ ảnh hưởng đến wAUC nhiều hơn $S_2$, hay nói cách khác diện tích ở vùng FPR thấp càng lớn thể hiện khả năng phát hiện tin ẩn đáng tin cậy hơn và tỉ lệ báo động sai sẽ thấp hơn, đó cũng chính là mục tiêu của cuộc thi này.\n",
    "\n",
    "## Mô tả bài toán:\n",
    "\n",
    "1. Chuẩn bị dữ liệu:\n",
    "    - Dữ liệu được chuẩn bị thông qua việc đọc các hình ảnh từ tập dữ liệu. Các hình ảnh được đọc, chuyển đổi từ BGR sang RGB, chuẩn hóa (chỉ số pixel được chia cho 255 để chuyển giá trị pixel về khoảng [0, 1]), và cuối cùng áp dụng các biến đổi.\n",
    "    - Tiền xử lý dữ liệu:\n",
    "        - Chuyển đổi hình ảnh sang định dạng tensor phù hợp với mô hình Pytorch.\n",
    "        - Áp dụng các phép biến đổi dữ liệu (như xoay, cắt, thu nhỏ, v.v.) để tăng cường dữ liệu và cải thiện khả năng tổng quát của mô hình.\n",
    "2. Tải Mô hình và Trọng số:\n",
    "    - Một mô hình học máy đã được huấn luyện trước đó (có thể là một mạng nơ-ron sâu) được tải với trọng số từ một tệp checkpoint. Điều này cho phép mô hình sử dụng kiến thức đã học từ quá trình huấn luyện trước đó.\n",
    "3. Dự đoán:\n",
    "    - Mô hình được sử dụng để thực hiện dự đoán trên tập dữ liệu kiểm tra. Dự đoán này được thực hiện bằng cách đưa hình ảnh qua mô hình để nhận đầu ra là xác suất của việc hình ảnh có bị nhúng dữ liệu hay không.\n",
    "4. Tính Xác suất:\n",
    "    - Đầu ra của mô hình (thường là logits) được chuyển qua hàm softmax để tính xác suất của mỗi lớp. Trong trường hợp này, xác suất của việc hình ảnh không chứa dữ liệu nhúng được tính toán, và xác suất của việc hình ảnh chứa dữ liệu nhúng được lấy là phần bù của xác suất này (1 - xác suất hình ảnh không chứa dữ liệu nhúng).\n",
    "5. Ghi Kết quả:\n",
    "    - Kết quả dự đoán, bao gồm tên hình ảnh và xác suất của việc hình ảnh chứa dữ liệu nhúng, được ghi vào một tệp CSV. Tệp này sau đó có thể được sử dụng để nộp lên các nền tảng đánh giá, như Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model EfficientNet - Pytorch:\n",
    "\n",
    "- __PyTorch__ là một thư viện mã nguồn mở phổ biến được sử dụng cho học máy, đặc biệt là trong lĩnh vực xử lý ảnh và thị giác máy tính. Nó cung cấp một tập hợp các công cụ và API mạnh mẽ để xây dựng, huấn luyện và triển khai các mô hình học sâu. PyTorch đóng vai trò quan trọng trong việc phát triển và sử dụng EfficientNet, nó cung cấp nền tảng và các công cụ cần thiết để xây dựng, huấn luyện và triển khai EfficientNet một cách hiệu quả.\n",
    "\n",
    "\n",
    "- __EfficientNet__ là một họ mô hình mạng neural sâu được phát triển bởi Google AI, được công bố lần đầu vào năm 2019. EfficientNet được thiết kế để đạt được hiệu suất cao nhất có thể về cả độ chính xác và tốc độ tính toán bằng cách sử dụng phương pháp mở rộng đồng thời độ sâu (depth), độ rộng (width) và độ phân giải (resolution) của mô hình. Một số đặc điểm chính của EfficientNet bao gồm:\n",
    "    - Compound Scaling: EfficientNet sử dụng một phương pháp mở rộng gọi là compound scaling, mở rộng đồng thời độ sâu (depth), độ rộng (width) và độ phân giải (resolution) của mạng neural theo một cách cân bằng và tối ưu.\n",
    "    - Baseline Model - EfficientNet-B0: EfficientNet bắt đầu với một mô hình cơ bản nhỏ gọi là EfficientNet-B0, được xây dựng bằng cách sử dụng kỹ thuật neural architecture search (NAS). Sau đó, các phiên bản lớn hơn (B1 đến B7) được tạo ra bằng cách mở rộng mô hình B0 theo phương pháp compound scaling.\n",
    "    - Hiệu suất cao: EfficientNet đạt được state-of-the-art accuracy trên nhiều tác vụ nhận dạng ảnh và cạnh tranh tốt về hiệu quả tính toán so với các mô hình khác như ResNet hay DenseNet.\n",
    "    - EfficientNet chủ yếu được sử dụng trong các tác vụ liên quan đến hình ảnh. Đầu vào thường là các hình ảnh với các kích thước khác nhau. Để đưa vào mô hình, các hình ảnh này thường được tiền xử lý như thay đổi kích thước, chuẩn hóa và các phép biến đổi khác (augmentation) để tăng tính đa dạng của dữ liệu huấn luyện.\n",
    "    - Đầu ra của mô hình EfficientNet thường là một vector xác suất cho mỗi lớp trong bài toán phân loại. Ví dụ, nếu bạn đang phân loại hình ảnh thành 4 loại khác nhau, đầu ra sẽ là một vector với 4 giá trị, mỗi giá trị biểu thị xác suất của hình ảnh thuộc về một lớp cụ thể.\n",
    "    \n",
    "    \n",
    "- __Trong đồ án này, EfficientNet có nhiệm vụ__: nhận diện và phân loại các hình ảnh dựa trên khả năng chứa thông tin ẩn, cách áp dụng:\n",
    "    - Đầu vào: Sử dụng hình ảnh từ tập dữ liệu, với mỗi hình ảnh được đánh dấu là \"bị nhúng dữ liệu\" hoặc \"không bị nhúng dữ liệu\".\n",
    "    - Mô hình EfficientNet: Chọn phiên bản phù hợp của EfficientNet (ví dụ: EfficientNet-B0 đến EfficientNet-B7) phù hợp với quy mô và yêu cầu tính toán của dự án.\n",
    "    - Tiền xử lý: Các hình ảnh được tiền xử lý trước khi đưa vào mô hình, bao gồm chuẩn hóa, thay đổi kích thước và các biến đổi khác để tăng tính đa dạng và khả năng tổng quát hóa của mô hình.\n",
    "    - Huấn luyện và đánh giá: Huấn luyện mô hình EfficientNet trên tập dữ liệu huấn luyện để học các đặc trưng của hình ảnh có chứa dữ liệu ẩn. Sau đó, đánh giá mô hình trên tập dữ liệu kiểm định để đo lường độ chính xác và hiệu suất của mô hình.\n",
    "    - Các bước cụ thể:\n",
    "        - Sử dụng EfficientNet để trích xuất đặc trưng từ hình ảnh.\n",
    "        - Áp dụng hàm mất mát phù hợp (ví dụ: LabelSmoothing) để huấn luyện mô hình.\n",
    "        - Đánh giá mô hình bằng các phép đo như AUC để đánh giá khả năng phân loại của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T05:27:13.239579Z",
     "iopub.status.busy": "2024-06-12T05:27:13.239217Z",
     "iopub.status.idle": "2024-06-12T05:27:29.080378Z",
     "shell.execute_reply": "2024-06-12T05:27:29.079265Z",
     "shell.execute_reply.started": "2024-06-12T05:27:13.239547Z"
    },
    "executionInfo": {
     "elapsed": 92195,
     "status": "ok",
     "timestamp": 1716396573136,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "xRBwhEgeLyuQ",
    "outputId": "2cddc839-888d-492a-9794-dc1d2edbbdca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet-pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch) (2.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=88417a385e2b30298eedf295b2074ad6704cb695e90d8879cd0eb7962467f176\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cài đặt thư viện EfficientNet - Pytorch:\n",
    "- Để có thể sử dụng mô hình `EfficientNet` được đào tạo cho phân loại ảnh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kYd_neDB7C4"
   },
   "source": [
    "PATH csv file: /content/drive/MyDrive/Alaska/train_75.csv\n",
    "'alaska2-image-steganalysis''train-75'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T05:27:33.080499Z",
     "iopub.status.busy": "2024-06-12T05:27:33.080107Z",
     "iopub.status.idle": "2024-06-12T05:27:36.452136Z",
     "shell.execute_reply": "2024-06-12T05:27:36.451180Z",
     "shell.execute_reply.started": "2024-06-12T05:27:33.080457Z"
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1716396691280,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "V-RnG9jIISix"
   },
   "outputs": [],
   "source": [
    "# library\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torch import nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from sklearn import metrics\n",
    "\n",
    "from glob import glob\n",
    "import random\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "from torch.utils.data.sampler import SequentialSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import những thư viện cần thiết\n",
    "Những thư viện cần thiết cho xử lý dữ liệu, mô hình mạng nơ-ron, tối ưu hóa, đánh giá hiệu quả của mô hình:\n",
    "- *__torch__*: thư viện `PyTorch`, dùng để xây dựng và huấn luyện các mô hình học sâu;\n",
    "\n",
    "\n",
    "- *__pandas__*: thao tác và phân tích dữ liệu dạng bảng (`DataFrame`);\n",
    "\n",
    "\n",
    "- *__cv2__*: thư viện `OpenCV`, dùng để xử lý hình ảnh và video;\n",
    "\n",
    "\n",
    "- *__albumentations__*: tăng cường dữ liệu (data augmentation) cho các ảnh;\n",
    "\n",
    "\n",
    "- *__ToTensorV2__*: chuyển đổi ảnh thành `tensor`, định dạng cần thiết cho `PyTorch`;\n",
    "\n",
    "\n",
    "- *__metrics__*: module `metrics` từ `scikit-learn`, chứa các hàm để đánh giá mô hình học máy;\n",
    "\n",
    "\n",
    "- *__GroupKFold__*: import lớp `GroupKFold` từ `scikit-learn`, một biến thể của *k-fold cross-validation* đảm bảo cùng một nhóm không được biểu diễn trong cả tập huấn luyện và kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run on local to make train.csv file\n",
    "'''\n",
    "\n",
    "# from glob import glob\n",
    "# import random\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "# def group_k_fold():\n",
    "#     dataset = []\n",
    "\n",
    "\n",
    "#     for label, kind in enumerate([\"Cover\", \"JMiPOD\", \"JUNIWARD\", \"UERD\"]):\n",
    "#         count = 0 \n",
    "#         for path in glob(\"../input/alaska2-image-steganalysis/Cover/*.jpg\"):\n",
    "#             dataset.append(\n",
    "#                 {\"kind\": kind, \"image_name\": path.split(\"\\\\\")[-1], \"label\": label}\n",
    "#             )\n",
    "\n",
    "#             count += 1\n",
    "#     print(count)\n",
    "\n",
    "#     random.shuffle(dataset)\n",
    "#     dataset = pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "#     gkf = GroupKFold(n_splits=5) # Chia data thanh 5 fold, \n",
    "                                    # moi fold co du 4 file .jpg cua 4 folder\n",
    "                                # Chon 1 fold làm valid data, 4 fold con lai la train data\n",
    "\n",
    "#     dataset.loc[:, \"fold\"] = 0\n",
    "#     print(dataset)\n",
    "#     for fold_number, (train_index, val_index) in enumerate(\n",
    "#         gkf.split(X=dataset.index, y=dataset[\"label\"], groups=dataset[\"image_name\"])\n",
    "#     ):\n",
    "#         dataset.loc[dataset.iloc[val_index].index, \"fold\"] = fold_number\n",
    "\n",
    "\n",
    "#     # save to /input/metadata/train_75.csv\n",
    "#     dataset.to_csv(\"../input/metadata/train_75.csv\", index=False)\n",
    "\n",
    "# group_k_fold()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tạo file 'train_75.csv' :\n",
    "* Chay dưới local để tạo;\n",
    "\n",
    "\n",
    "* Chứa thông tin *metadata* của các hình ảnh trong bộ dữ liệu, gồm nhãn, loại ảnh, thông tin về fold để phục vụ cho việc huấn luyện mô hình với kỹ thuật *k-fold cross-validation*. \n",
    "\n",
    "\n",
    "* Về *k-fold cross-validation*:\n",
    "    * Là 1 kỹ thuật phổ biến để đánh giá hiệu suất của mô hình học máy. Nó hoạt động bằng cách chia tập dữ liệu thành *k* phần (*folds*) và sử dụng từng phần để luân phiên làm tập huấn luyện và tập kiểm tra. Quá trình này được lặp lại *k* lần, đảm bảo rằng mỗi phần dữ liệu được sử dụng một lần làm tập kiểm tra.   \n",
    "    \n",
    "    * Cách thực hiện:\n",
    "        * Chia tập dữ liệu thành *k* phần (*folds*) có kích thước bằng nhau - trong đồ án này chúng ta sẽ chia `k = 5`;\n",
    "        * Với mỗi nhóm: chọn nhóm hiện tại làm tập kiểm tra (`valid_dataset`) và *k-1* nhóm còn lại làm tập huấn luyện (`train_dataset`) ==> huấn luyện mô hình học máy trên tập huấn luyện ==> đánh giá hiệu suất mô hình trên tập kiểm tra;\n",
    "        *  Tính toán hiệu suất trung bình của mô hình trên mỗi nhóm.    \n",
    "        \n",
    "    * Ưu điểm: \n",
    "        * Ước tính độ chính xác mô hình một cách khách quan, giúp giảm thiểu ảnh hưởng của việc chia dữ liệu ngẫu nhiên, cung cấp kết quả đánh giá mô hình ổn định và đáng tin cậy.\n",
    "        * Khi mô hình *overfitting* với tập huấn luyện, nó có thể hoạt động kém trên dữ liệu mới. *K-fold CV* có thể giúp phát hiện tình trạng *overfitting* bằng cách theo dõi hiệu suất mô hình trên các tập kiểm tra khác nhau.\n",
    "\n",
    "\n",
    "* Giải thích chi tiết:\n",
    "    * Tạo mảng `dataset` lưu trữ thông tin các mẫu dữ liệu\n",
    "    * Duyệt qua 4 folders *Cover, JMiPOD, JUNIWARD, UERD* và lặp qua tất quả file *.jpg* của mỗi folder;\n",
    "    * Với mỗi file tạo 1 từ điển gồm `kind` (loại), `image_name` (tên) và `label` (nhãn) và `append` vào mảng `dataset`;\n",
    "    * Dùng `shuffle` để trộn ngẫu nhiên danh sách `dataset` nhằm đảm bảo mô hình được huấn luyện một cách hiệu quả và có tính tổng quát tốt, giúp tránh hiện tượng *overfitting*, không phụ thuộc vào thứ tự của dữ liệu.\n",
    "    * Sau đó tiến hành khởi tạo `gkf - GroupKFold` là chia dữ liệu thành 5 folds, mỗi fold sẽ có 4 loại ảnh (*Cover, JMiPOD, JUNIWARD, UERD*) từ 4 thư mục khác nhau và đảm bảo rằng cùng một nhóm không xuất hiện trong cả tập huấn luyện và tập kiểm thử. Một fold được chọn làm dữ liệu kiểm thử (valid data), và 4 fold còn lại là dữ liệu huấn luyện (train data). \n",
    "    * Gán `fold` cho mỗi mẫu bằng cách duyệt qua các `fold` được tạo và gán giá trị fold tương ứng cho mỗi mẫu trong `DataFrame` `dataset`.\n",
    "    * Cuối cùng, `DataFrame` `dataset` được lưu vào một file `CSV - train_75.CSV`, cho phép lưu trữ và sử dụng lại dữ liệu đã được chia fold một cách dễ dàng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T05:54:11.043900Z",
     "iopub.status.busy": "2024-06-12T05:54:11.043544Z",
     "iopub.status.idle": "2024-06-12T05:54:11.326070Z",
     "shell.execute_reply": "2024-06-12T05:54:11.325202Z",
     "shell.execute_reply.started": "2024-06-12T05:54:11.043874Z"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1716397202887,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "OpsBEWjjOHxE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JUNIWARD</td>\n",
       "      <td>20402.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cover</td>\n",
       "      <td>28617.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JUNIWARD</td>\n",
       "      <td>07694.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JUNIWARD</td>\n",
       "      <td>51201.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JMiPOD</td>\n",
       "      <td>03417.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>JUNIWARD</td>\n",
       "      <td>52099.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>UERD</td>\n",
       "      <td>50987.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>JMiPOD</td>\n",
       "      <td>69068.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>UERD</td>\n",
       "      <td>18377.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>JMiPOD</td>\n",
       "      <td>43327.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            kind image_name  label  fold\n",
       "0       JUNIWARD  20402.jpg      2     1\n",
       "1          Cover  28617.jpg      0     4\n",
       "2       JUNIWARD  07694.jpg      2     1\n",
       "3       JUNIWARD  51201.jpg      2     3\n",
       "4         JMiPOD  03417.jpg      1     0\n",
       "...          ...        ...    ...   ...\n",
       "299995  JUNIWARD  52099.jpg      2     0\n",
       "299996      UERD  50987.jpg      3     1\n",
       "299997    JMiPOD  69068.jpg      1     4\n",
       "299998      UERD  18377.jpg      3     2\n",
       "299999    JMiPOD  43327.jpg      1     0\n",
       "\n",
       "[300000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constant\n",
    "MODEL = \"efficientnet-b2\"\n",
    "CSV_DIR = \"/kaggle/input/train-75/\" # Thu mục chứa csv thông tin metadata input\n",
    "DATA_ROOT_PATH = \"/kaggle/input/alaska2-image-steganalysis\" # thư mục chứa data của đề bài\n",
    "OUTPUT_DIR = \"/kaggle/working/submission.csv\"\n",
    "data = pd.read_csv('/kaggle/input/train-75/train_75.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant: \n",
    "\n",
    "\n",
    "- Thiết lập các hằng số là các đường dẫn quan trọng;\n",
    "- Đọc dữ liệu từ file `train-75.csv` vừa tạo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T05:54:17.968743Z",
     "iopub.status.busy": "2024-06-12T05:54:17.967939Z",
     "iopub.status.idle": "2024-06-12T05:54:17.977720Z",
     "shell.execute_reply": "2024-06-12T05:54:17.976502Z",
     "shell.execute_reply.started": "2024-06-12T05:54:17.968705Z"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1716397168367,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "6k_A-ch6A63v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_75.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "config.py\n",
    "'''\n",
    "class TrainGlobalConfig:\n",
    "    csv_file = \"train_75.csv\"  # can change to train_90.csv or train_95.csv\n",
    "    fold_number = 2\n",
    "    num_workers = 4\n",
    "    batch_size = 16\n",
    "    n_epochs = 2 # so spoch huan luyen, 2 vi khong co time\n",
    "    lr = 2e-4\n",
    "\n",
    "    verbose = True # kiem soat viec in thong bao khi huan luyen\n",
    "    verbose_step = 1\n",
    "\n",
    "    step_scheduler = True  # cap nhat ti le hoc tap sau moi buoc toi uu hoa\n",
    "    valid_scheduler = False  # khong cap nhat ti le hoc tap trong qua trinh validation\n",
    "\n",
    "    SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "    scheduler_params = dict(\n",
    "        max_lr=lr,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=None,\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy=\"cos\",\n",
    "        cycle_momentum=True,\n",
    "        div_factor=10.0,\n",
    "    )\n",
    "print(TrainGlobalConfig.csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config: \n",
    "\n",
    "\n",
    "- Cài đặt lớp `TrainGlobalConfig` gồm một số cấu hình cơ bản, định nghĩa các biến toàn cục như:\n",
    "    - `csv_file`, `fold_number` (chọn fold làm tập `valid_dataset` để test), `lr` (learning rate - kiểm soát mức độ mô hình cập nhật trọng số của nó dựa trên các lỗi trong quá trình training), `verbose` (kiểm soát in thông báo trong khi huấn luyện), `step_scheduler` và `valid_scheduler` (kiểm soát việc cập nhật learning rate ), ...\n",
    "    - `scheduler_params`: từ điển chứa các tham số về việc cập nhật tỷ lệ học tập trong quá trình training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T05:54:20.781994Z",
     "iopub.status.busy": "2024-06-12T05:54:20.781644Z",
     "iopub.status.idle": "2024-06-12T05:54:20.786957Z",
     "shell.execute_reply": "2024-06-12T05:54:20.785989Z",
     "shell.execute_reply.started": "2024-06-12T05:54:20.781966Z"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1716396706027,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "NGFi_u1QLR02"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "net.py\n",
    "'''\n",
    "def get_net():\n",
    "    net = EfficientNet.from_pretrained(MODEL)\n",
    "    net._fc = nn.Linear(in_features=1408, out_features=4, bias=True)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_net()`:\n",
    "- Tạo mô hình mạng nơ-ron sử dụng `EfficientNet` đã được huấn luyện trước (`pretrained`);\n",
    "- Thay đổi lớp fully connected (FC) cuối cùng với 1408 đặc trưng đầu vào và 4 đầu ra để phù hợp với tác vụ phân loại vào 4 lớp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T05:54:23.752914Z",
     "iopub.status.busy": "2024-06-12T05:54:23.752551Z",
     "iopub.status.idle": "2024-06-12T05:54:23.758603Z",
     "shell.execute_reply": "2024-06-12T05:54:23.757578Z",
     "shell.execute_reply.started": "2024-06-12T05:54:23.752886Z"
    },
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1716396713411,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "DajGTWrTOowg"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "utils.py\n",
    "'''\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `seed_everything(seed)`:\n",
    "\n",
    "\n",
    "- Đặt giá trị seed cố định cho tất cả các thư viện và môi trường có thể ảnh hưởng đến tính ngẫu nhiên trong quá trình chạy chương trình như `random`, biến môi trường `PYTHONHASHSEED`, thư viện` NumPy`, thư viện `PyTorch`.\n",
    "- Giúp đảm bảo tính nhất quán, đảm bảo rằng kết quả của chương trình là có thể tái tạo được"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T04:09:48.648416Z",
     "iopub.status.busy": "2024-06-12T04:09:48.646852Z",
     "iopub.status.idle": "2024-06-12T04:09:48.666483Z",
     "shell.execute_reply": "2024-06-12T04:09:48.664904Z",
     "shell.execute_reply.started": "2024-06-12T04:09:48.648363Z"
    },
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1716396732101,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "42Ebdgk2K6XE"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "dataset.py\n",
    "DATA_ROOT_PATH : /kaggle/input/alaska2-image-steganalysis\n",
    "'''\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, df, num_classes=4, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.num_classes = num_classes\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # image la data anh index.jpg cua thu muc \"kind\"\n",
    "        # target la vector co dang [x, x, x, x] xac dinh loai anh\n",
    "        filename = (self.df[\"kind\"].values)[index] + \"/\" + (self.df[\"image_name\"].values)[index] \n",
    "        image = cv2.imread(f\"{DATA_ROOT_PATH}/{filename}\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {\"image\": image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample[\"image\"]\n",
    "\n",
    "        label_idx = (self.df[\"label\"].values)[index]\n",
    "        target = self.onehot(self.num_classes, label_idx) \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.df[\"label\"].values)\n",
    "\n",
    "    def onehot(self, num_classes, target):\n",
    "        vec = torch.zeros(num_classes, dtype=torch.float32)\n",
    "        vec[target] = 1.0\n",
    "        return vec\n",
    "\n",
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, image_names, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_names = image_names\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        image = cv2.imread(f\"{DATA_ROOT_PATH}/Test/{image_name}\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {\"image\": image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample[\"image\"]\n",
    "\n",
    "        return image_name, image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_names.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `class Dataset` và `class TestDataset`:\n",
    "\n",
    "\n",
    "- Xử lý dữ liệu huấn luyện (có nhãn) và dữ liệu kiểm tra (không có nhãn);\n",
    "- Giải thích chi tiết:\n",
    "\n",
    "\n",
    "- `Class Dataset`:\n",
    "    - Phương thức khởi tạo `__init__`:  `transforms` - các biến đổi áp dụng cho ảnh nhằm chuẩn hóa, tăng cường dữ liệu.\n",
    "    - Phương thức lấy mẫu dựa vào index `__getitem__(self, index)`: \n",
    "        - Từ `index` xác định tên file và đường dẫn tương ứng, chuyển ảnh từ BGR thành RGB do OpenCV đọc hình ảnh theo thứ tự BGR (Blue, Green, Red) thay vì thứ tự RGB (Red, Green, Blue),  chuẩn hóa giá trị pixel về [0, 1] (Giá trị pixel ban đầu thường nằm trong phạm vi từ 0 đến 255. Chuẩn hóa giá trị pixel về phạm vi từ 0 đến 1 giúp quá trình học của mô hình học máy diễn ra ổn định và nhanh chóng hơn. → image /= 255.0), sau đó áp dụng các phương thức `transform`, tạo nhãn dưới dạng vector one-hot dựa vào nhãn của ảnh.\n",
    "        - Trả về cặp ảnh và nhãn tương ứng.\n",
    "    - Phương thức lấy độ dài dataset `__len__`;\n",
    "    - Phương thức lấy danh sách nhãn `getlabels`;\n",
    "    - Phương thức chuyển đổi nhãn sang dạng one-hot `onehot`:\n",
    "        - Tạo một vector zeros với kích thước bằng số lớp [x,x,x,x];\n",
    "        - Đặt giá trị 1.0 tại vị trí tương ứng với nhãn của ảnh. (vd: [0, 0, 1.0, 0] )\n",
    "    - Tạo nhãn với vecctor one-hot (dành cho các bài toán với số lớp lớn hơn 2) nhằm: \n",
    "        - Mỗi lớp được biểu diễn rõ ràng và độc lập bằng một vector mà trong đó chỉ có một phần tử là 1 và tất cả các phần tử khác là 0\n",
    "        - Tương thích với các hàm tính mất mát - loss function như hàm mất mát `cross-entropy` yêu cầu đầu vào là dạng one-hot\n",
    "        - Tránh việc khiến mô hình hiểu lầm khi sử dụng nhãn số nguyên (0, 1, 2, 3) là nhãn có số cao hơn thì quan trọng hơn\n",
    "        - Giúp việc cập nhật trọng số trong quá trình học của mô hình trở nên hiệu quả hơn.\n",
    "        \n",
    "        \n",
    "- `Class TestDataset`:\n",
    "    - Các phương thức tương tự Dataset nhưng TestDataset không cần nhãn vì nó được thiết kế để đánh giá hiệu suất của mô hình sau khi mô hình đã được huấn luyện.\n",
    "    - Trong quá trình kiểm tra, mô hình sẽ dự đoán nhãn cho các mẫu trong tập kiểm tra và các dự đoán này sẽ được so sánh với nhãn thực tế để đánh giá độ chính xác, độ nhạy và các chỉ số khác. Vì thế, trong lớp `TestDataset`, nhãn không cần thiết vì nhiệm vụ của nó chỉ là cung cấp dữ liệu đầu vào cho mô hình. \n",
    "    - Nếu nhãn được sử dụng trong tập kiểm tra, có nguy cơ mô hình có thể \"nhìn thấy\" hoặc sử dụng nhãn trong quá trình dự đoán, điều này sẽ dẫn đến rò rỉ dữ liệu và kết quả đánh giá sẽ không chính xác. Bằng cách không bao gồm nhãn trong `TestDataset`, chúng ta đảm bảo rằng mô hình chỉ dựa vào dữ liệu đầu vào để đưa ra dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T04:09:51.601826Z",
     "iopub.status.busy": "2024-06-12T04:09:51.600262Z",
     "iopub.status.idle": "2024-06-12T04:09:51.610759Z",
     "shell.execute_reply": "2024-06-12T04:09:51.609351Z",
     "shell.execute_reply.started": "2024-06-12T04:09:51.601773Z"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1716396743487,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "OgW395coNNQO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "transform.py\n",
    "'''\n",
    "def get_augs():\n",
    "    train_augs = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(height=512, width=512, p=1.0),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.RandomRotate90(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0, # p = 1.0 means that the transform will be applied to all images\n",
    "    )\n",
    "\n",
    "    valid_augs = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "    return train_augs, valid_augs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_augs()`:\n",
    "- Giúp tạo ra các phép biến đổi cần thiết để chuẩn bị dữ liệu cho quá trình huấn luyện và kiểm tra mô hình. Các phép biến đổi này bao gồm thay đổi kích thước ảnh, lật ảnh, xoay ảnh và chuyển đổi ảnh thành tensor. Sử dụng các phép biến đổi này giúp tăng cường dữ liệu (Data Augmentation), cải thiện khả năng tổng quát hóa, đảm bảo tính chính xác của mô hình và chuẩn bị dữ liệu ở định dạng phù hợp cho quá trình huấn luyện với PyTorch.\n",
    "\n",
    "\n",
    "- Trả về hai đối tượng albumentations.Compose, mỗi đối tượng chứa một chuỗi các phép biến đổi (augmentation) ảnh được áp dụng cho tập huấn luyện (train) và tập xác thực (valid). Các phép biến đổi này được thực hiện bằng thư viện albumentations, một thư viện phổ biến cho việc tiền xử lý và tăng cường dữ liệu ảnh.\n",
    "\n",
    "\n",
    "- Đối với dữ liệu huấn luyện `train_augs`:\n",
    "    - Thực hiện các phép biến đổi như thay đổi kích thước, lật ngang, lật dọc, xoay ảnh 90 độ, chuyển đổi ảnh thành tensor PyTorch để phù hợp với đầu vào của mô hình. \n",
    "    - Tỷ lệ thực hiện `p = 1.0` tương đương 100% tức là toàn bộ ảnh đều thực hiện biến đổi hay `p = 0.5` tương đương 50%\n",
    "    \n",
    "    \n",
    "- Đối với dữ liệu huấn luyện `valid_augs`:\n",
    "    - Chỉ thực hiện thay đổi kích thước và chuyển đổi ảnh thành tensor PyTorch. Các biến đổi này ít đa dạng hơn so với quá trình huấn luyện để đảm bảo tính chính xác và khách quan khi đánh giá mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T04:10:24.448694Z",
     "iopub.status.busy": "2024-06-12T04:10:24.448190Z",
     "iopub.status.idle": "2024-06-12T04:10:24.459258Z",
     "shell.execute_reply": "2024-06-12T04:10:24.457565Z",
     "shell.execute_reply.started": "2024-06-12T04:10:24.448661Z"
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1716396747682,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "3XZZipwXNlMu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "loss.py\n",
    "'''\n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing=0.05):\n",
    "        super().__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        if self.training:\n",
    "            logits = logits.float()\n",
    "            targets = targets.float()\n",
    "\n",
    "            log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "            nll_loss = (-log_probs * targets).sum(-1)\n",
    "            smooth_loss = -log_probs.mean(dim=-1)\n",
    "\n",
    "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "\n",
    "            return loss.mean()\n",
    "\n",
    "        else:\n",
    "            return F.cross_entropy(logits, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính toán loss:\n",
    "- Định nghĩa lớp `LabelSmoothing` kế thừa từ lớp `nn.Module` của `Pytorch` => thực hiện kỹ thuật làm mịn nhãn, nằm trong 1 phần của hàm tính mất mát - loss function trong quá trình huấn luyện mô hình.\n",
    "- __Ý tưởng__: Label Smoothing là một kỹ thuật giúp giảm hiện tượng quá mức tự tin (overconfidence) của mô hình bằng cách điều chỉnh nhãn mục tiêu, thay vì sử dụng nhãn \"cứng\" (0 hoặc 1) trong vector one-hot, vd: (0, 0, 1, 0), nhãn được làm mềm bằng cách phân bổ một lượng nhỏ độ tin cậy vào các lớp khác, vd: (0.0125, 0.0125; 0.9625; 0.0125)\n",
    "- __Công thức__: kĩ thuật làm mượt label có dạng one-hot theo công thức sau:\n",
    "<center>\\[ q_i = \\begin{cases} \n",
    "1 - \\varepsilon & \\text{if } i = y, \\\\\n",
    "\\frac{\\varepsilon}{K - 1} & \\text{otherwise},\n",
    "\\end{cases} \\]</center>\n",
    "\n",
    "với K là số class (*K = 4*) và ε   là một hằng số nhỏ do ta chọn . Kĩ thuật này làm giảm sự tự tin thái quá của model, làm giảm khả năng overfit.\n",
    "- Phương thức khởi tạo `__init__(self, smoothing = 0,05)` với độ làm mịn nhãn `smoothing = 0,05`, độ tin cậy của nhãn thực `confidence = 1.0 - smoothing`.\n",
    "\n",
    "\n",
    "- Phương thức `forward(self, logits, targets)`: phương thức chính để tính mất mát. Việc làm mềm nhãn (`targets`) không được thực hiện trực tiếp mà là thông qua cách tính toán mất mát để giả lập việc làm mềm nhãn, bằng cách phân bổ một lượng nhỏ độ tin cậy đến tất cả các lớp, bao gồm cả lớp đúng và các lớp sai, vd: (0, 0, 1, 0) => (0.0125, 0.0125; 0.9625; 0.0125). Điều này giúp giảm bớt sự tự tin quá mức của mô hình vào nhãn thực tế và khuyến khích mô hình phân bổ một lượng nhỏ xác suất vào các lớp khác, qua đó làm mềm nhãn một cách gián tiếp.\n",
    "\n",
    "    - Nếu đang trong giai đoạn huấn luyện (`self.training`):\n",
    "        - Chuyển `logits` (đầu ra của mô hình trước khi áp dụng softmax) và `targets` (nhãn thực tế) sang kiểu `float`\n",
    "        - Tính log của softmax của `logits` để chuyển đổi `logits` thành `log-probabilities`\n",
    "        - Tính toán `nll_loss` (negative log likelihood loss) - tính mất mát đối với các nhãn thực tế\n",
    "        - Tính toán `smooth_loss` - tính bằng cách lấy trung bình của `log-probabilities` \n",
    "        - Tính tổng hợp mất mát - `loss`: kết hợp `nll_loss` và `smooth_loss` với trọng số được xác định bởi `confidence` và `smoothing`\n",
    "        - Trả về trung bình của tổng mất mát trên tất cả các mẫu. \n",
    "        \n",
    "    - Nếu đang trong quá trình kiểm tra: hàm mất mát sẽ sử dụng `F.cross_entropy` trực tiếp trên `logits` và `targets` mà không áp dụng làm mịn nhãn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T04:09:55.345481Z",
     "iopub.status.busy": "2024-06-12T04:09:55.344934Z",
     "iopub.status.idle": "2024-06-12T04:09:55.374985Z",
     "shell.execute_reply": "2024-06-12T04:09:55.373231Z",
     "shell.execute_reply.started": "2024-06-12T04:09:55.345435Z"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1716396752974,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "FQ_vGReHNxLV"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "metric.py\n",
    "'''\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def alaska_weighted_auc(y_true, y_valid):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/anokas/weighted-auc-metric-updated\n",
    "    \"\"\"\n",
    "    tpr_thresholds = [0.0, 0.4, 1.0]\n",
    "    weights = [2, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_valid, pos_label=1)\n",
    "\n",
    "    # size of subsets\n",
    "    areas = np.array(tpr_thresholds[1:]) - np.array(tpr_thresholds[:-1])\n",
    "\n",
    "    # The total area is normalized by the sum of weights such that the final weighted AUC is between 0 and 1.\n",
    "    normalization = np.dot(areas, weights)\n",
    "\n",
    "    competition_metric = 0\n",
    "    for idx, weight in enumerate(weights):\n",
    "        y_min = tpr_thresholds[idx]\n",
    "        y_max = tpr_thresholds[idx + 1]\n",
    "        mask = (y_min < tpr) & (tpr < y_max)\n",
    "\n",
    "        if sum(mask) != 0:\n",
    "\n",
    "            x_padding = np.linspace(fpr[mask][-1], 1, 100)\n",
    "\n",
    "            x = np.concatenate([fpr[mask], x_padding])\n",
    "            y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n",
    "            y = y - y_min  # normalize such that curve starts at y=0\n",
    "            score = metrics.auc(x, y)\n",
    "\n",
    "        else:\n",
    "            score = 1.0\n",
    "\n",
    "        submetric = score * weight\n",
    "        # best_subscore = (y_max - y_min) * weight\n",
    "        competition_metric += submetric\n",
    "\n",
    "    return competition_metric / normalization\n",
    "\n",
    "\n",
    "class RocAucMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = np.array([0, 1])\n",
    "        self.y_pred = np.array([0.5, 0.5])\n",
    "        self.score = 0\n",
    "\n",
    "    def update(self, y_pred, y_true):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:, 0]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = alaska_weighted_auc(self.y_true, self.y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lớp `AverageMeter(object)':\n",
    "- Tính toán và lưu giá trị trung bình với các phương thức `__init__(self)`, `reset(self)`, `update(self, val, n =1)` - cập nhật giá trị trung bình.\n",
    "\n",
    "### Hàm `alaska_weighted_auc(y_true, y_valid)`:\n",
    "\n",
    "\n",
    "- Hàm tính toán AUC có trọng số, một biến thể của AUC (Area Under the Curve) dành riêng cho bài toán phát hiện ẩn dữ liệu của cuộc thi <font color = blue> __Alaska2__</font>  trên <font color=blue> __Kaggle__</font>, với các phạm vi khác nhau của `TPR` (True Positive Rate) có mức độ quan trọng khác nhau cho bài toán.\n",
    "- __Bước 1: Định nghĩa ngưỡng và trọng số:__\n",
    "    - `tpr_thresholds` định nghĩa các ngưỡng cho TPR. Trong trường hợp này, có ba ngưỡng: 0.0, 0.4, và 1.0.\n",
    "    - `weights` định nghĩa trọng số cho mỗi phạm vi giữa các ngưỡng TPR. Có hai trọng số: 2 cho phạm vi từ 0.0 đến 0.4 và 1 cho phạm vi từ 0.4 đến 1.0.\n",
    "- __Bước 2: Tính toán ROC Curve__\n",
    "    - Sử dụng `metrics.roc_curve` để tính toán FPR (False Positive Rate), TPR, và ngưỡng từ y_true (nhãn thực) và y_valid (xác suất dự đoán là dương tính).\n",
    "- __Bước 3: Chuẩn bị cho việc tính toán AUC có trọng số__\n",
    "    - Tính `areas` là diện tích của mỗi phạm vi giữa các ngưỡng TPR.\n",
    "    - Tính `normalization` là tổng trọng số của các phạm vi, được sử dụng để chuẩn hóa AUC về [0, 1].\n",
    "- __Bước 4: Tính toán AUC có trọng số__\n",
    "    - Lặp qua mỗi phạm vi giữa các ngưỡng TPR:\n",
    "        - Tính `mask` để xác định các điểm nằm trong phạm vi hiện tại.\n",
    "        - Nếu có điểm trong phạm vi:\n",
    "            - Tính `x_padding` để đảm bảo rằng đường cong ROC kết thúc tại FPR = 1.\n",
    "            - Tạo `x` và `y` bằng cách kết hợp các giá trị FPR và TPR với `x_padding` và giá trị `y_max` tương ứng.\n",
    "            - Chuẩn hóa `y` để đường cong bắt đầu từ 0.\n",
    "            - Tính `score` là AUC của phạm vi hiện tại.\n",
    "        - Nếu không có điểm nào trong phạm vi, gán `score` là 1.0.\n",
    "        - Tính `submetric` là AUC có trọng số cho phạm vi hiện tại.\n",
    "    - Cộng dồn `submetric` vào `competition_metric`.\n",
    "- __Bước 5: Trả về AUC có trọng số chuẩn hóa__\n",
    "    - Chia `competition_metric` cho `normalization` để đảm bảo giá trị cuối cùng nằm trong khoảng từ 0 đến 1.\n",
    "    \n",
    "### Lớp `RocAucMeter`:\n",
    "- Theo dõi và tính toán AUC (Area Under the Curve) có trọng số cho một tập dữ liệu dự đoán và nhãn thực tế trong quá trình huấn luyện hoặc kiểm thử mô hình.\n",
    "- Phương thức `__init__(self)`: gọi phương thức `reset` để thiết lập các giá trị ban đầu.\n",
    "- Phương thức `reset(self)`: \n",
    "    - Đặt lại `y_true` và `y_pred` thành mảng numpy với giá trị khởi tạo là `[0, 1]` và `[0.5, 0.5]` tương ứng, đảm bảo rằng cả hai mảng đều có ít nhất một giá trị dương và một giá trị âm, tránh lỗi khi tính toán AUC.\n",
    "    - `score` được đặt lại thành 0, chuẩn bị cho việc tính toán mới.\n",
    "- Phương thức `update(self, y_pred, y_true)`: cập nhật giá trị dự đoán `y_pred` và giá trị thực `y_true` sau đó tính toán AUC có trọng số dùng hàm `alaska_weighted_auc`.\n",
    "    - `y_true` được chuyển thành mảng `numpy`, sử dụng `argmax` để chọn lớp có xác suất cao nhất từ đầu ra của mô hình, sau đó giới hạn giá trị trong khoảng [0, 1] và chuyển thành kiểu int.\n",
    "    - `y_pred` được xử lý để lấy xác suất của lớp 0 (giả sử lớp 0 là lớp quan tâm) bằng cách sử dụng hàm `softmax`, sau đó lấy `1 - `giá trị đó để phản ánh xác suất của lớp đối diện.\n",
    "    - Cập nhật `self.y_true` và `self.y_pred` bằng cách ghép mảng mới vào mảng hiện tại.\n",
    "    - Tính toán `score` mới sử dụng hàm `alaska_weighted_auc` với `self.y_true` và `self.y_pred` cập nhật.\n",
    "- Thuộc tính `avg`: Một property Python, trả về giá trị `score` hiện tại, cho phép truy cập dễ dàng và đọc được giá trị AUC có trọng số mà không cần gọi một phương thức cụ thể.\n",
    "\n",
    "\n",
    "- __Hàm softmax__:\n",
    "    - Hàm softmax là một hàm kích hoạt được sử dụng chủ yếu ở lớp đầu ra của các mô hình phân loại đa lớp. Nó chuyển đổi một véc-tơ của giá trị thô (còn gọi là logits) từ lớp đầu ra của mô hình thành một véc-tơ của giá trị xác suất có tổng bằng 1. Cụ thể, hàm softmax đảm bảo rằng mỗi giá trị đầu ra nằm trong khoảng (0, 1) và tổng của tất cả các giá trị đầu ra bằng 1, làm cho chúng có thể được giải thích như là xác suất.\n",
    "    - Tác dụng của hàm Softmax:\n",
    "        - Chuyển đổi Logits thành Xác suất: Hàm softmax chuyển đổi các giá trị đầu ra của mô hình (logits) thành xác suất bằng cách sử dụng công thức toán học đặc biệt, giúp dễ dàng giải thích kết quả đầu ra của mô hình.\n",
    "        - So sánh giữa các Lớp: Bằng cách chuyển đổi đầu ra thành xác suất, softmax giúp so sánh trực tiếp mức độ \"tự tin\" của mô hình đối với mỗi lớp, làm cho việc lựa chọn lớp dự đoán cuối cùng trở nên dễ dàng hơn.\n",
    "        - Tối Ưu Hóa Dễ Dàng: Khi kết hợp với hàm mất mát như cross-entropy, việc sử dụng softmax giúp quá trình tối ưu hóa (học) của mô hình trở nên hiệu quả hơn, vì gradient của hàm mất mát có thể được tính toán một cách chính xác và ổn định."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T04:09:59.612071Z",
     "iopub.status.busy": "2024-06-12T04:09:59.611513Z",
     "iopub.status.idle": "2024-06-12T04:09:59.650509Z",
     "shell.execute_reply": "2024-06-12T04:09:59.647473Z",
     "shell.execute_reply.started": "2024-06-12T04:09:59.612028Z"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1716396757904,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "I2F5CL6xO7hg"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "learner.py\n",
    "'''\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class Learner:\n",
    "    def __init__(self, model, config, base_dir=\"./\"):\n",
    "        self.model = model.cuda()\n",
    "        self.config = config\n",
    "\n",
    "        self.base_dir = base_dir\n",
    "        self.log_path = f\"{self.base_dir}/log.txt\"\n",
    "        self.best_loss = 1e5\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        self.scheduler = config.SchedulerClass(\n",
    "            self.optimizer, **config.scheduler_params\n",
    "        )\n",
    "        self.criterion = LabelSmoothing().cuda()\n",
    "        self.log(\"Learner prepared.\")\n",
    "\n",
    "    def fit(self, train_loader, valid_loader):\n",
    "        for epoch in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f\"\\n{timestamp}\\n\")\n",
    "\n",
    "            # Training\n",
    "            t = time.time()\n",
    "            train_loss, auc_scores = self.train(train_loader)\n",
    "\n",
    "            self.log(\n",
    "                f\"[RESULT]: Train. Epoch: {epoch}, train_loss: {train_loss.avg:.5f}, auc_score: {auc_scores.avg:.5f}, time: {(time.time() - t):.5f}\"\n",
    "            )\n",
    "            self.save(f\"{self.base_dir}/last-checkpoint.bin\")\n",
    "\n",
    "            # Validation\n",
    "            t = time.time()\n",
    "            valid_loss, auc_scores = self.validation(valid_loader)\n",
    "\n",
    "            self.log(\n",
    "                f\"[RESULT]: Val. Epoch: {epoch}, valid_loss: {valid_loss.avg:.5f}, auc_score: {auc_scores.avg:.5f}, time: {(time.time() - t):.5f}\"\n",
    "            )\n",
    "            if valid_loss.avg < self.best_loss:\n",
    "                self.best_loss = valid_loss.avg\n",
    "                self.save(\n",
    "                    f\"{self.base_dir}/fold{self.config.fold_number}-checkpoint-{str(epoch).zfill(3)}epoch.bin\"\n",
    "                )\n",
    "                for path in sorted(\n",
    "                    glob(\n",
    "                        f\"{self.base_dir}/fold{self.config.fold_number}-checkpoint-*epoch.bin\"\n",
    "                    )\n",
    "                )[:-3]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.valid_scheduler:\n",
    "                self.scheduler.step(metrics=valid_loss.avg)\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        train_loss = AverageMeter()\n",
    "        auc_scores = RocAucMeter()\n",
    "\n",
    "        t = time.time()\n",
    "        for step, (images, targets) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "                    print(\n",
    "                        f\"Train step {step}/{len(train_loader)}, Learning rate = {1e6*lr:.6f}e-6, \"\n",
    "                        + f\"Train loss: {train_loss.avg:.5f}, AUC score: {auc_scores.avg:.5f}, \"\n",
    "                        + f\"Time: {(time.time() - t):.5f}\",\n",
    "                        end=\"\\r\",\n",
    "                    )\n",
    "\n",
    "            images = images.cuda().float()\n",
    "            targets = targets.cuda().float()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            preds = self.model(images)\n",
    "            loss = self.criterion(preds, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            auc_scores.update(preds, targets)\n",
    "            batch_size = images.shape[0]\n",
    "            train_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "        return train_loss, auc_scores\n",
    "\n",
    "    def validation(self, valid_loader):\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        valid_loss = AverageMeter()\n",
    "        auc_scores = RocAucMeter()\n",
    "\n",
    "        t = time.time()\n",
    "        for step, (images, targets) in enumerate(valid_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f\"Validation step {step}/{len(valid_loader)}, \"\n",
    "                        + f\"Valid loss: {valid_loss.avg:.5f}, AUC score: {auc_scores.avg:.5f}, \"\n",
    "                        + f\"Time: {(time.time() - t):.5f}\",\n",
    "                        end=\"\\r\",\n",
    "                    )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                images = images.cuda().float()\n",
    "                targets = targets.cuda().float()\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "\n",
    "                auc_scores.update(preds, targets)\n",
    "                batch_size = images.shape[0]\n",
    "                valid_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "        return valid_loss, auc_scores\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "                \"best_loss\": self.best_loss,\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        self.best_loss = checkpoint[\"best_loss\"]\n",
    "\n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, \"a+\") as logger:\n",
    "            logger.write(f\"{message}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lớp `Learner`:\n",
    "- Huấn luyện và đánh giá một mô hình học sâu với PyTorch, gồm các phương thức:\n",
    "\n",
    "- Phương thức khởi tạo `__init__(self, model, config, base_dir=\"./\")`:\n",
    "    - `model.cuda()`: chuyển mô hình sang thiết bị CUDA (GPU) để tăng tốc độ tính toán.\n",
    "    - `self.config`: lưu cấu hình huấn luyện.\n",
    "    - `self.base_dir`: đường dẫn lưu các tệp liên quan\n",
    "    - `self.log_path`: đường dẫn đến tệp log.\n",
    "    - `self.best_loss`: khởi tạo giá trị best loss với một số lớn (1e5).\n",
    "    - `self.optimizer`: Khởi tạo optimizer AdamW với các tham số của mô hình và learning rate từ cấu hình.\n",
    "    - `self.scheduler`: Khởi tạo scheduler dựa trên lớp và tham số từ cấu hình.\n",
    "    - `self.criterion`: Khởi tạo hàm mất mát Label Smoothing và đưa nó lên GPU.\n",
    "    - `self.log(\"Learner prepared.\")`: Ghi log rằng Learner đã được chuẩn bị.\n",
    "    \n",
    "    \n",
    "- Phương thức `fit(self, train_loader, valid_loader)`: huấn luyện và đánh giá mô hình cho từng epoch\n",
    "    - Lặp qua mỗi epoch:\n",
    "        - Kiểm tra verbose: nếu bật, in ra timestamp bắt đầu epoch.\n",
    "        - Huấn luyện:\n",
    "            - Gọi hàm `train` (được định nghĩa ở dưới) để huấn luyện trên tập `train_loader`, nhận về `train_loss` và `auc_scores`.\n",
    "            - Ghi log kết quả huấn luyện (mất mát trung bình, AUC score trung bình, thời gian).\n",
    "            - Lưu checkpoint mô hình với tên `last-checkpoint.bin`.\n",
    "        - Đánh giá:\n",
    "            - Gọi hàm `validation` để đánh giá trên `valid_loader`.\n",
    "            - Ghi log kết quả đánh giá (mất mát trung bình, AUC score trung bình, thời gian).\n",
    "            - Kiểm tra nếu mất mát đánh giá trung bình nhỏ hơn `best_loss`:\n",
    "                - Cập nhật `best_loss`.\n",
    "                - Lưu checkpoint mô hình với tên theo fold, epoch (ví dụ: `fold{fold_number}-checkpoint-{epoch}-epoch.bin)`.\n",
    "                - Xóa các checkpoint cũ hơn (giữ lại 3 checkpoint gần nhất).\n",
    "            - Kiểm tra `valid_scheduler`: nếu có, điều chỉnh learning rate của scheduler dựa trên mất mát đánh giá trung bình.\n",
    "\n",
    "\n",
    "- Phương thức `train(self, train_loader)`: thực hiện quá trình huấn luyện mô hình bằng cách lặp qua tập dữ liệu, tính toán mất mát, cập nhật mô hình dựa trên mất mát này, và theo dõi hiệu suất huấn luyện qua mất mát và điểm số AUC.\n",
    "    - Huấn luyện mô hình trên bộ dữ liệu `train_loader`.\n",
    "    - Chuyển mô hình sang chế độ huấn luyện (`model.train()`).\n",
    "    - Khởi tạo các object `AverageMeter` để theo dõi mất mát trung bình và `RocAucMeter` để theo dõi AUC score trung bình.\n",
    "    - Lặp qua các batch dữ liệu:\n",
    "        - Kiểm tra `verbose`: nếu bật và đủ điều kiện (`step % verbose_step == 0`), in ra thông tin về learning rate, mất mát trung bình, AUC score trung bình, thời gian.\n",
    "        - Chuyển dữ liệu hình ảnh và nhãn - `images` và `targets` được chuyển lên GPU (nếu có) và chuyển đổi sang dạng số thực.\n",
    "        - Tính toán Mất mát và Cập nhật Mô hình:\n",
    "            - Xóa gradient cũ bằng `self.optimizer.zero_grad()`.\n",
    "            - Dự đoán (`preds`) từ mô hình dựa trên `images`. (`preds = self.model(images)`).\n",
    "            - Tính toán mất mát (`loss`) bằng hàm `criterion` giữa dự đoán và mục tiêu thực tế.\n",
    "            - Thực hiện backpropagation - lan truyền ngược gradient (`loss.backward()`).\n",
    "            - Cập nhật trọng số mô hình (`optimizer.step()`).\n",
    "        - Kiểm tra `step_scheduler`: nếu có, điều chỉnh learning rate của scheduler.\n",
    "        - Cập nhật `auc_scores` và `train_loss` với kết quả của batch hiện tại.\n",
    "        - Cuối cùng, phương thức trả về `train_loss` và `auc_scores` để theo dõi hiệu suất huấn luyện.\n",
    "       \n",
    "        \n",
    "- Phương thức `validation(self, valid_loader)`: thực hiện quá trình đánh giá mô hình trên tập dữ liệu kiểm định bằng cách lặp qua tập dữ liệu, tính toán mất mát mà không cập nhật mô hình, và theo dõi hiệu suất kiểm định qua mất mát và điểm số AUC.\n",
    "    - Đánh giá mô hình trên bộ dữ liệu `valid_loader`.\n",
    "    - Chuyển mô hình sang chế độ đánh giá (`model.eval()`).\n",
    "    - Khởi tạo các object `AverageMeter` để theo dõi mất mát trung bình và `RocAucMete`r để theo dõi AUC score trung bình.\n",
    "    - Lặp qua các batch dữ liệu: \n",
    "        - Kiểm tra `verbose`: nếu bật và đủ điều kiện (`step % verbose_step == 0`), in ra thông tin về mất mát trung bình, AUC score trung bình, thời gian.\n",
    "        - Xử lý Dữ liệu và Tính toán Mất mát Mà Không Cập nhật Mô hình:\n",
    "            - Sử dụng `torch.no_grad()` để vô hiệu hóa việc tính toán gradient, giảm bớt việc sử dụng bộ nhớ và tăng tốc độ tính toán.\n",
    "            - Dữ liệu `images` và `targets` được chuyển lên GPU (nếu có) và chuyển đổi sang dạng số thực.\n",
    "            - Dự đoán (`preds`) từ mô hình dựa trên `images`.\n",
    "            - Tính toán mất mát giữa dự đoán và mục tiêu thực tế.\n",
    "       - Cập nhật `auc_scores` và `valid_loss` với kết quả từ batch hiện tại.\n",
    "       - Cuối cùng, phương thức trả về `valid_loss` và `auc_scores` để theo dõi hiệu suất kiểm định.\n",
    "           \n",
    "           \n",
    "- Phương thức `save(self, path)`: lưu trạng thái hiện tại của quá trình huấn luyện vào một file theo đường dẫn được cung cấp (`path`), gồm: \n",
    "    - self.model.state_dict(): Trạng thái của mô hình, bao gồm các giá trị trọng số và bias của tất cả các lớp trong mô hình.\n",
    "    - self.optimizer.state_dict(): Trạng thái của trình tối ưu hóa, lưu trữ các thông tin như learning rate hiện tại và các tham số khác liên quan đến quá trình cập nhật trọng số.\n",
    "    - self.scheduler.state_dict(): Trạng thái của trình lập lịch learning rate, lưu các thông tin về learning rate hiện tại và lịch trình thay đổi learning rate.\n",
    "    - self.best_loss: Giá trị mất mát xác nhận tốt nhất đạt được trong quá trình huấn luyện tính đến thời điểm lưu.\n",
    "    \n",
    "    \n",
    "- Phương thức `load(self, path)`:  nạp trạng thái huấn luyện được lưu trước đó từ một file theo đường dẫn được cung cấp (`path`) và phục hồi các thành phần của quá trình huấn luyện.\n",
    "\n",
    "\n",
    "- Phương thức `log(self, message)`: Ghi log thông tin - ghi một thông báo (`message`) vào file log.\n",
    "    - Kiểm tra thuộc tính `verbose` trong `self.config`: nếu là True, thông báo sẽ được in ra console.\n",
    "    - Ghi thông báo vào file `self.log_path` ở chế độ mở để thêm (`\"a+\"`). Điều này cho phép ghi nhiều thông báo vào cùng một file log theo thứ tự thời gian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T04:10:05.724782Z",
     "iopub.status.busy": "2024-06-12T04:10:05.724159Z",
     "iopub.status.idle": "2024-06-12T04:10:05.738053Z",
     "shell.execute_reply": "2024-06-12T04:10:05.736306Z",
     "shell.execute_reply.started": "2024-06-12T04:10:05.724737Z"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1716397285458,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "ROgWiB76N9fx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train.py\n",
    "'''\n",
    "\n",
    "def train():\n",
    "    SEED = 42\n",
    "    seed_everything(SEED)\n",
    "    csv_file = TrainGlobalConfig.csv_file\n",
    "    df = pd.read_csv(CSV_DIR + csv_file)\n",
    "\n",
    "    train_augs, valid_augs = get_augs()\n",
    "    train_dataset = Dataset(\n",
    "        df=df[df[\"fold\"] != TrainGlobalConfig.fold_number], # Lấy hàng có giá trị fold khác fold_number trong config\n",
    "        transforms=train_augs,\n",
    "    )\n",
    "            \n",
    "    valid_dataset = Dataset(\n",
    "        df=df[df[\"fold\"] == TrainGlobalConfig.fold_number], # ngược lại\n",
    "        transforms=valid_augs,\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=BalanceClassSampler(\n",
    "            labels=train_dataset.get_labels(), mode=\"downsampling\"\n",
    "        ),\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(valid_dataset),\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    TrainGlobalConfig.scheduler_params[\"steps_per_epoch\"] = (\n",
    "        len(train_dataset) // TrainGlobalConfig.batch_size\n",
    "    )\n",
    "\n",
    "    net = get_net().cuda()\n",
    "    learner = Learner(model=net, config=TrainGlobalConfig)\n",
    "    learner.fit(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hàm `train()`: \n",
    "- Mô tả quy trình huấn luyện một mô hình học máy, từ việc chuẩn bị dữ liệu đến việc khởi tạo và huấn luyện mô hình, cụ thể:\n",
    "- Khởi tạo Seed: Đặt seed (`SEED = 42`) để đảm bảo tính nhất quán và tái lập được của quá trình huấn luyện.\n",
    "- Đọc Dữ liệu: Sử dụng `pandas` để đọc dữ liệu từ một tệp CSV, đường dẫn được xác định bởi `TrainGlobalConfig.csv_file` và `CSV_DIR`.\n",
    "- Chuẩn bị Dữ liệu và Augmentation:\n",
    "    - `get_augs()` trả về các phép biến đổi (augmentations) cho dữ liệu huấn luyện và kiểm định.\n",
    "    - Tạo hai tập dữ liệu, `train_dataset` và `valid_dataset`, dựa trên giá trị của cột `fold`. Dữ liệu được chia theo giá trị `fold` để phục vụ cho quá trình kiểm định chéo (cross-validation).\n",
    "- Khởi tạo DataLoader:\n",
    "    - `train_loader` sử dụng `BalanceClassSampler` để cân bằng số lượng mẫu giữa các lớp thông qua downsampling, giúp giảm thiểu vấn đề mất cân bằng lớp.\n",
    "    - `valid_loader` không cần cân bằng lớp và sử dụng `SequentialSampler` để duyệt qua dữ liệu kiểm định theo thứ tự.\n",
    "- Cấu hình `Scheduler`: Cập nhật `scheduler_params` trong `TrainGlobalConfig` bằng cách tính toán số bước mỗi epoch dựa trên kích thước của tập dữ liệu huấn luyện và kích thước batch.\n",
    "- Khởi tạo Mô hình và Learner:\n",
    "    - `get_net()` tạo mô hình và chuyển nó lên GPU .\n",
    "    - `Learner` được khởi tạo với mô hình và cấu hình huấn luyện. `Learner` là một lớp trừu tượng hóa quá trình huấn luyện, bao gồm việc theo dõi mất mát, tối ưu hóa, và lập lịch tốc độ học.\n",
    "- Huấn luyện Mô hình: Cuối cùng, sử dụng phương thức fit của `Learner` để bắt đầu quá trình huấn luyện mô hình với `train_loader` và `valid_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T14:37:51.217547Z",
     "iopub.status.busy": "2024-05-30T14:37:51.217297Z",
     "iopub.status.idle": "2024-05-30T18:19:06.520127Z",
     "shell.execute_reply": "2024-05-30T18:19:06.518783Z",
     "shell.execute_reply.started": "2024-05-30T14:37:51.217527Z"
    },
    "executionInfo": {
     "elapsed": 482,
     "status": "error",
     "timestamp": 1716397288791,
     "user": {
      "displayName": "Thế Nguyễn",
      "userId": "10566603595114768909"
     },
     "user_tz": -420
    },
    "id": "bNCKURgOPBV_",
    "outputId": "b30d22b8-69bf-403f-facc-8b9e89463d5c"
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHeagEsINR95"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "inference.py\n",
    "Chạy với data test và ghi auc vào submission.csv\n",
    "'''\n",
    "# Thay doi file .bin neu co cai tot hon\n",
    "CHECKPOINT_PATH = \"/kaggle/working/last-checkpoint.bin\"\n",
    "\n",
    "def list_files_in_dir(path):\n",
    "    # Ensure the path ends with a slash\n",
    "    if not path.endswith('/'):\n",
    "        path += '/'\n",
    "    \n",
    "    # Use glob to list all files in the directory\n",
    "    files = glob(path + '*')\n",
    "    \n",
    "    return files\n",
    "\n",
    "files = list_files_in_dir(CHECKPOINT_PATH)\n",
    "print(files)\n",
    "\n",
    "class DatasetSubmissionRetriever:\n",
    "    def __init__(self, image_names, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_names = image_names\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        image = cv2.imread(f\"{DATA_ROOT_PATH}/Test/{image_name}\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {\"image\": image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample[\"image\"]\n",
    "\n",
    "        return image_name, image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_names.shape[0]\n",
    "\n",
    "\n",
    "def submiss_run():\n",
    "    _, valid_augs = get_augs()\n",
    "    test_dataset = DatasetSubmissionRetriever(\n",
    "        image_names=np.array(\n",
    "            [\n",
    "                path.split(\"/\")[-1]\n",
    "                for path in glob(\"/kaggle/input/alaska2-image-steganalysis/Test/*.jpg\")\n",
    "            ]\n",
    "        ),\n",
    "        transforms=valid_augs,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    net = get_net()\n",
    "    net.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    net = net.cuda()\n",
    "    result = {\"Id\": [], \"Label\": []}\n",
    "    for step, (image_names, images) in enumerate(test_loader):\n",
    "        print(step, end=\"\\r\")\n",
    "\n",
    "        y_pred = net(images.cuda())\n",
    "        y_pred = (\n",
    "            1 - F.softmax(y_pred, dim=1).data.cpu().numpy()[:, 0]\n",
    "        )  # first column corresponds to 'proba of no hidden code'\n",
    "\n",
    "        result[\"Id\"].extend(image_names)\n",
    "        result[\"Label\"].extend(y_pred)\n",
    "\n",
    "    submission = pd.DataFrame(result)\n",
    "    submission.to_csv(OUTPUT_DIR, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "- Thực hiện quy trình dự đoán trên tập dữ liệu kiểm tra, sử dụng một mô hình đã được huấn luyện và lưu trữ trong một checkpoint, và sau đó ghi kết quả dự đoán vào một tệp CSV (`submission.csv`)\n",
    "- `CHECKPOINT_PATH` chứa đường dẫn đến tệp checkpoint mà từ đó mô hình sẽ được tải.\n",
    "- `list_files_in_dir` là một hàm để liệt kê tất cả các tệp trong một thư mục chỉ định.\n",
    "- `DatasetSubmissionRetriever` là một lớp dataset được tạo để xử lý việc tải và biến đổi hình ảnh từ tập dữ liệu kiểm tra.\n",
    "- Hình ảnh được đọc và chuyển đổi từ BGR sang RGB, sau đó được chuẩn hóa bằng cách chia cho 255.0. Nếu có biến đổi (`transforms`) được cung cấp, chúng sẽ được áp dụng cho hình ảnh\n",
    "- Tạo `test_dataset` sử dụng `DatasetSubmissionRetriever` với danh sách tên hình ảnh được lấy từ thư mục kiểm tra.\n",
    "- `test_loader` được tạo để tải dữ liệu kiểm tra với kích thước batch, số lượng worker, và cài đặt khác.\n",
    "- Tải Checkpoint và Mô hình:\n",
    "    - Tải checkpoint từ đường dẫn đã định nghĩa.\n",
    "    - Khởi tạo mô hình và tải trạng thái mô hình từ checkpoint.\n",
    "    - Chuyển mô hình lên GPU (nếu có).\n",
    "- Dự đoán và Ghi Kết quả:\n",
    "    - Lặp qua `test_loader`, thực hiện dự đoán trên từng batch.\n",
    "    - Tính xác suất của lớp mục tiêu bằng cách sử dụng hàm softmax và lấy phần bù của xác suất cho lớp \"không có mã ẩn\" (`1 - softmax`).\n",
    "    - Lưu tên hình ảnh và xác suất dự đoán vào từ điển `result`.\n",
    "- Tạo và Ghi Tệp `Submission`:\n",
    "    - Chuyển đổi `result` thành DataFrame `submission`.\n",
    "    - Ghi DataFrame vào tệp CSV `submission.csv` trong thư mục `OUTPUT_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T16:41:25.359262Z",
     "iopub.status.busy": "2024-05-31T16:41:25.358848Z",
     "iopub.status.idle": "2024-05-31T16:41:25.365237Z",
     "shell.execute_reply": "2024-05-31T16:41:25.364132Z",
     "shell.execute_reply.started": "2024-05-31T16:41:25.359235Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "check log.txt\n",
    "'''\n",
    "try:\n",
    "  with open(\"/kaggle/working/log.txt\", 'r') as f:\n",
    "    log_contents = f.read()\n",
    "  print(f\"The LOG variable contains: {log_contents}\")\n",
    "except FileNotFoundError:\n",
    "  print(\"Error: The file /kaggle/working/log.txt doesn't exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check log:\n",
    "- kiểm tra sự tồn tại của tệp log.txt trong thư mục /kaggle/working/, đọc và in nội dung của nó nếu tệp tồn tại. Nếu tệp không tồn tại, một thông báo lỗi sẽ được hiển thị."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T18:19:06.560307Z",
     "iopub.status.busy": "2024-05-30T18:19:06.55992Z",
     "iopub.status.idle": "2024-05-30T18:20:27.388234Z",
     "shell.execute_reply": "2024-05-30T18:20:27.387012Z",
     "shell.execute_reply.started": "2024-05-30T18:19:06.560276Z"
    }
   },
   "outputs": [],
   "source": [
    "submiss_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết quả huấn luyện mô hình:\n",
    "\n",
    "### Kết quả nộp file trên Kaggle : \n",
    "- Link code đã nộp trên Kaggle: [Submission](https://www.kaggle.com/code/aleskab400/alaska2zero/notebook)\n",
    "- Kết quả tốt nhất: \n",
    "    - Private Score: 0.753\n",
    "    - Public Score: 0.776\n",
    "- Nhận xét: \n",
    "    - Kết quả trên phụ thuộc vào tài nguyên sử dụng gồm: loại mô hình EfficientNet B2, số Epoch huấn luyện = 1\n",
    "    - Để nâng cao kết quả, có thể áp dụng mô hình EfficientNet B4 trở lên, thêm số Epoch huấn luyện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết luận:\n",
    "\n",
    "\n",
    "### Khó khăn gặp phải:\n",
    "- Các mảng kiến thức mới về machine learning, các model huấn luyện là một thách thức lớn.\n",
    "- Phần cứng cũng là một hạn chế cho việc thực hiện huấn luyện dữ liệu, mặc dù có thể sử dụng tài nguyên miễn phí trên Kaggle những với tập dữ liệu huấn luyện khá lớn (75.000 x 4 ) cũng dẫn đến việc mất nhiều thời gian huấn luyện.\n",
    "- Một số khó khăn trong làm việc nhóm như quản lý thời gian và phân chia công việc.\n",
    "\n",
    "\n",
    "### Kinh nghiệm và kiến thức đạt được :\n",
    "- Có kiến thức về các phương pháp ẩn dữ liệu khác nhau, đặc biệt là việc ẩn dữ liệu liên quan đến việc ẩn dữ liệu trong các tệp ảnh JPEG.\n",
    "- Mang đến cơ hội khám phá các ứng dụng của Machine Learning trong lĩnh vực An ninh mạng, trong việc phát hiện dữ liệu bí mật.\n",
    "- Có thêm kinh nghiệm thực tế với các kỹ thuật xử lý hình ảnh, hiểu được cách các ảnh JPEG được cấu trúc và xử lý, cũng như cách dữ liệu có thể được nhúng vào chúng.\n",
    "- Có kiến thức về Machine Learning, các kỹ thuật tiền xử lý, tạo model... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1117522,
     "sourceId": 19991,
     "sourceType": "competition"
    },
    {
     "datasetId": 5196312,
     "sourceId": 8670650,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py311env",
   "language": "python",
   "name": "py311env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
